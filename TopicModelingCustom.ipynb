{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "from stop_words import get_stop_words\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "path = os.path.expanduser('~/TopicModelResearch/chatlogs/questions.txt')\n",
    "doc_set = []\n",
    "with open(path, 'rb') as chatQuestions:\n",
    "    for line in chatQuestions:\n",
    "        doc_set.append(line.split(\"==>\")[1].strip(\"\\n\").replace(\":\",\"\").replace(\"#\",\"\").replace(\"/\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Adding Custom stopwords to en_stop\n",
    "Custom_stops = en_stop\n",
    "Custom_stops.append(u'just'); Custom_stops.append(u'want'); Custom_stops.append(u'need'); \n",
    "Custom_stops.append(u'can'); Custom_stops.append(u'get'); Custom_stops.append(u'Custom'); \n",
    "Custom_stops.append(u'will'); Custom_stops.append(u'please'); Custom_stops.append(u'chat');\n",
    "Custom_stops.append(u'able'); Custom_stops.append(u'thank'); Custom_stops.append(u'you'); \n",
    "Custom_stops.append(u'thank you'); Custom_stops.append(u'know'); Custom_stops.append(u'issue');\n",
    "Custom_stops.append(u'sorry'); Custom_stops.append(u'understand'); Custom_stops.append(u'make');\n",
    "Custom_stops.append(u'understood'); Custom_stops.append(u'ensure');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list for tokenized documents in loop\n",
    "question_texts = []\n",
    "# loop through document list\n",
    "\n",
    "for i in doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    raw = i.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in Custom_stops]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    question_texts.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "question_dictionary = corpora.Dictionary(question_texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "question_corpus = [question_dictionary.doc2bow(text) for text in question_texts]\n",
    "\n",
    "\n",
    "# generate LDA model\n",
    "question_ldamodel = gensim.models.ldamodel.LdaModel(question_corpus, num_topics=10, \n",
    "                                                    id2word = question_dictionary, alpha='auto', passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saveing the question model\n",
    "question_ldamodel.save(os.path.expanduser('~/TopicModelResearch/chatlogs/questionLDA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = (question_ldamodel.print_topics(num_topics=10, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.160*internet + 0.112*slow + 0.088*connect + 0.075*correct + 0.071*speed\n",
      "0.051*today + 0.045*concern + 0.042*assur + 0.037*chat + 0.037*rest\n",
      "0.123*modem + 0.046*new + 0.033*cabl + 0.023*activ + 0.021*router\n",
      "0.096*account + 0.079*email + 0.035*address + 0.028*correct + 0.027*new\n",
      "0.095*servic + 0.035*bill + 0.025*correct + 0.024*like + 0.023*internet\n",
      "0.087*wifi + 0.059*connect + 0.037*password + 0.035*correct + 0.028*router\n",
      "0.112*speed + 0.043*internet + 0.033*get + 0.030*mbp + 0.028*download\n",
      "0.070*internet + 0.061*connect + 0.041*work + 0.032*time + 0.021*modem\n",
      "0.046*servic + 0.038*appoint + 0.037*instal + 0.035*cancel + 0.033*correct\n",
      "0.055*tv + 0.043*onlin + 0.029*watch + 0.028*access + 0.023*tri\n"
     ]
    }
   ],
   "source": [
    "for item in x: print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answerTokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "answerPath = os.path.expanduser('~/TopicModelResearch/chatlogs/answers.txt')\n",
    "answer_doc_set = []\n",
    "with open(answerPath, 'rb') as chatAnswers:\n",
    "    for line in chatAnswers:\n",
    "        answer_doc_set.append(line.split(\"==>\")[1].strip(\"\\n\").replace(\":\",\" \").replace(\"#\",\" \").replace(\"/\",\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list for tokenized documents in loop\n",
    "answer_texts = []\n",
    "\n",
    "# loop through document list\n",
    "for i in answer_doc_set:\n",
    "    \n",
    "    # clean and tokenize document string\n",
    "    answer_raw = i.lower()\n",
    "    answer_tokens = answerTokenizer.tokenize(answer_raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    answer_stopped_tokens = [i for i in answer_tokens if not i in Custom_stops]\n",
    "    \n",
    "    # stem tokens\n",
    "    answer_stemmed_tokens = [p_stemmer.stem(i) for i in answer_stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    answer_texts.append(answer_stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn our tokenized documents into a id <-> term dictionary\n",
    "answer_dictionary = corpora.Dictionary(answer_texts)\n",
    "    \n",
    "# convert tokenized documents into a document-term matrix\n",
    "answer_corpus = [answer_dictionary.doc2bow(text) for text in answer_texts]\n",
    "\n",
    "# generate LDA model\n",
    "answer_ldamodel = gensim.models.ldamodel.LdaModel(answer_corpus, num_topics=10, \n",
    "                                                  id2word = answer_dictionary, alpha='auto', passes=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_topics = (answer_ldamodel.print_topics(num_topics=10, num_words=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the answer model\n",
    "answer_ldamodel.save(os.path.expanduser('~/TopicModelResearch/chatlogs/answerLDA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055*password + 0.034*wifi + 0.022*network + 0.020*connect + 0.018*click\n",
      "0.029*account + 0.024*servic + 0.018*support + 0.018*inform + 0.017*hello\n",
      "0.041*connect + 0.017*modem + 0.017*internet + 0.017*signal + 0.015*check\n",
      "0.035*technician + 0.023*schedul + 0.021*00 + 0.019*appoint + 0.017*ticket\n",
      "0.024*packag + 0.022*servic + 0.018*internet + 0.015*month + 0.015*speed\n",
      "0.028*custom + 0.024*help + 0.017*today + 0.016*day + 0.015*take\n",
      "0.073*home + 0.031*xfiniti + 0.031*control + 0.021*secur + 0.020*screen\n",
      "0.040*account + 0.024*email + 0.016*may + 0.013*onlin + 0.012*use\n",
      "0.062*modem + 0.033*connect + 0.028*back + 0.021*speed + 0.014*devic\n",
      "0.019*connect + 0.018*account + 0.017*internet + 0.016*address + 0.016*let\n"
     ]
    }
   ],
   "source": [
    "for item in answer_topics: print item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic = getTopicForQuery(question_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = gensim.similarities.MatrixSimilarity(question_ldamodel[question_corpus], num_features=10)\n",
    "index.save(\"question_simIndex.index\") # generate document similarity by lda values - set to 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'cant', 'remember', 'password']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get topic for query\n",
    "question_query = 'I cant remember my password'\n",
    "tokens = tokenizer.tokenize(question_query)\n",
    "\n",
    "# remove stop words from tokens\n",
    "question_query = [i for i in tokens if not i in Custom_stops]\n",
    "question_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'I', u'cant', u'rememb', u'password']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_q = [p_stemmer.stem(i) for i in question_query] # stemming the query\n",
    "vec_bow = question_dictionary.doc2bow(stem_q) # convert question query into bag of words vector\n",
    "vec_lda = question_ldamodel[vec_bow] # From the train topic model obtain the closesest topic distribution for query\n",
    "sims = index[vec_lda]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1]) # get similar documents to query sorted by similarity score\n",
    "stem_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Issue unable to download Norton\n",
      "My Issue Norton Security Suite\n",
      "I understand that you want to know your password. My Issue my security password\n",
      "My Issue Norton Security suite.\n",
      "My Issue Norton security suite\n",
      "My Issue Norton Security Suite\n",
      "My Issue How do I password lock my wifi\n",
      "My Issue change security question\n",
      "My Issue Need to change wifi password\n",
      "My Issue Norton security pin\n"
     ]
    }
   ],
   "source": [
    "for k in sims[:10]:\n",
    "    print doc_set[k[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getting similar answers ##### DONT RUN THIS CELL AT DEMO ########\n",
    "answer_index = gensim.similarities.MatrixSimilarity(answer_ldamodel[answer_corpus], num_features=10)\n",
    "answer_index.save(\"answer_simIndex.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer_vec_bow = answer_dictionary.doc2bow(stem_q)\n",
    "vec_answer_lda = answer_ldamodel[answer_vec_bow]\n",
    "answer_sims = answer_index[vec_answer_lda]\n",
    "answer_sims = sorted(enumerate(answer_sims), key=lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Removed\n",
      "\n",
      "\n",
      "Text Removed\n",
      "\n",
      "\n",
      "Text Removed\n",
      "\n",
      "\n",
      "Text Removed\n",
      "\n",
      "\n",
      "Text Removed\n",
      "\n",
      "\n",
      "Text Removed \n",
      "\n",
      "\n",
      "Text Removed\n",
      "\n",
      "\n",
      "Text Removed.\n",
      "\n",
      "\n",
      "Text Removed \n",
      "\n",
      "\n",
      " Text Removed",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in answer_sims[:10]:\n",
    "    print answer_doc_set[k[0]]\n",
    "    print \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(answer_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
